{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Week 2A: Accessing data from Reddit\n\n## Overview\n\nReddit is an online bulletin board system to host user-generated content, e.g., text, image, video, audio `posts`. It is categorized into `subreddits` which are communities or user-groups meant to serve as a bulletin board on a specific topic or for a specific group of people. The users can `comment` on posts, which can then be `upvoted` or `downvoted` by other users. Each subreddit is moderated by `moderators` who try to enforce community rules to the comments and discussion therein.\n\n## APIs\n\nThere are two APIs that are widely used to scrape data from Reddit\n- Reddit API (https://www.reddit.com/dev/api/) - This is the most detailed API with endpoints that can enable us to find almost anything on Reddit. There is a Python wrapper, `praw`,  that helps us access this API (https://praw.readthedocs.io/en/stable/index.html). \n- Pushshift API (https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/) - Pushshift is a big-data storage and analytics project that enables access to the Reddit data albeit with some delay related to specific content (e.g, editing of comments might not be included instantly). It allows us to process data before accessing it, e.g., counting comments by specific users. In a raw Reddit API, we will need to do it locally, while Pushshift API enables us to do this without the hassle of downloading data. There is a Python wrapper, `psaw`, that helps us access Reddit data easily using Pushshit API (https://pypi.org/project/psaw/). \n\nIn this exercise, we will use `psaw`. ",
   "metadata": {
    "cell_id": "33988ed5-9285-4a27-94cb-29f1ee359d7f",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 189.1999969482422
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "fcd55917-69fd-4606-b96e-602f4aa41b68",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4f02b477",
    "execution_start": 1645983168884,
    "execution_millis": 9085,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "%%capture\n# We call the Python package manager pip to install the psaw package\n# (advanced) Using ! in ipython notebook runs the command in the bash shell and not in the python; try running !ls in a new cell\n!pip install --upgrade psaw",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Pushshift API\n\nThere are two ways to access this API \n- Plain API through https://api.pushshift.io/.  \n- (advanced) Elasticsearch search engine through https://elastic.pushshift.io/. This search engine is designed for fast aggregation and query on big-data. \n\nThe full API is documented here https://github.com/pushshift/api. However, in this exercise, we will learn how to use the plain API through https://api.pushshift.io/ and `psaw`. ",
   "metadata": {
    "cell_id": "ee91b1c6-a550-4a6e-ab96-2896e8aaa2f9",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 186.60000610351562
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Querying Pushshift API manually\n\nTo use the Pushshift API, we need to know the endpoints that are accessible. Each endpoint serves a specific purpose. There are two endpoints available for this API:\n- `/reddit/search/comment` to search for comments\n- `/reddit/search/submission` to search for posts\n\nThus, for example, if we need to search for comments, they can be accessed via https://api.pushshift.io/reddit/search/comment. \n\nOnce we have the correct address, we need a query to search the database. Any data that is sent to an API is included only after a `?` in the URL link. For example, if we need to look up submissions that have word \"science\" in them, our query will look like:\n\n```\nhttps://api.pushshift.io/reddit/search/submission/?q=science\n```\n\nIf we click on the above link or copy and paste the above link in any browser, we will see a JSON response from this enddpoint giving us 25 (by default) most recent posts containing the word \"science\". Each post is in the form of key-value pair. An example response of a post is as follows:",
   "metadata": {
    "cell_id": "0899368b-0953-4a50-a5cb-9aa08fe652d6",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 282.20001220703125
   }
  },
  {
   "cell_type": "markdown",
   "source": "        {\n            \"all_awardings\": [],\n            \"allow_live_comments\": false,\n            \"author\": \"Own_Professional_190\",\n            \"author_flair_css_class\": null,\n            \"author_flair_richtext\": [],\n            \"author_flair_text\": null,\n            \"author_flair_type\": \"text\",\n            \"author_fullname\": \"t2_jaz08fd5\",\n            \"author_is_blocked\": false,\n            \"author_patreon_flair\": false,\n            \"author_premium\": false,\n            \"awarders\": [],\n            \"can_mod_post\": false,\n            \"contest_mode\": false,\n            \"created_utc\": 1644227451,\n            \"domain\": \"self.UToledo\",\n            \"full_link\": \"https://www.reddit.com/r/UToledo/comments/smmgy3/questions_about_transferring/\",\n            \"gildings\": {},\n            \"id\": \"smmgy3\",\n            \"is_created_from_ads_ui\": false,\n            \"is_crosspostable\": true,\n            \"is_meta\": false,\n            \"is_original_content\": false,\n            \"is_reddit_media_domain\": false,\n            \"is_robot_indexable\": true,\n            \"is_self\": true,\n            \"is_video\": false,\n            \"link_flair_background_color\": \"\",\n            \"link_flair_richtext\": [],\n            \"link_flair_text_color\": \"dark\",\n            \"link_flair_type\": \"text\",\n            \"locked\": false,\n            \"media_only\": false,\n            \"no_follow\": true,\n            \"num_comments\": 0,\n            \"num_crossposts\": 0,\n            \"over_18\": false,\n            \"permalink\": \"/r/UToledo/comments/smmgy3/questions_about_transferring/\",\n            \"pinned\": false,\n            \"retrieved_on\": 1644227461,\n            \"score\": 1,\n            \"selftext\": \"Hi, \\n\\nI am an international student looking for universities to transfer. I heard that Toledo is known for its engineering program and co-op program. I am interested in computer science and data science. Can anybody tell me about general thoughts on university life at Toledo? It can include anything - reputation, class experience, dorm life, life outside of university, and so on. \\n\\nThank you in advance and stay safe :D\",\n            \"send_replies\": true,\n            \"spoiler\": false,\n            \"stickied\": false,\n            \"subreddit\": \"UToledo\",\n            \"subreddit_id\": \"t5_2wpwg\",\n            \"subreddit_subscribers\": 182,\n            \"subreddit_type\": \"public\",\n            \"thumbnail\": \"self\",\n            \"title\": \"Questions about transferring\",\n            \"total_awards_received\": 0,\n            \"treatment_tags\": [],\n            \"upvote_ratio\": 1.0,\n            \"url\": \"https://www.reddit.com/r/UToledo/comments/smmgy3/questions_about_transferring/\"\n        }",
   "metadata": {
    "cell_id": "e9813b74-047c-4b55-ada0-9a218ba86e79",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 1277.199951171875
   }
  },
  {
   "cell_type": "markdown",
   "source": "There are many ways to query this API. Head over to https://github.com/pushshift/api#search-parameters-for-comments to check the paramaters that you can pass to the API to enhance your queries.",
   "metadata": {
    "cell_id": "37116a42-6101-4bab-90b0-65390cf62fda",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "\n### Understanding the JSON response\n\nHere are a few keys returned by the API and what they mean. Most of them are self-explanatory, and which ones are needed will depend heavily on the specific use cases. \n\n----\n\n| **Key**        \t|   \t| **Description**                                               \t|\n|----------------\t|---\t|---------------------------------------------------------------\t|\n| _url_          \t|   \t| url of the `post` or `comment`                                \t|\n| _author_       \t|   \t| username of the redditor who created this `post` or `comment` \t|\n| _created_utc_  \t|   \t| time in UTC when this `post` or `comment` was created         \t|\n| _subreddit_    \t|   \t| `subreddit` on which this `post` or `comment` was created     \t|\n| _title_        \t|   \t| title of the `post`                                           \t|\n| _selftext_     \t|   \t| content of the `post` or the `comment`                        \t|\n| _retrieved_on_ \t|   \t| time in UTC when this data was extracted by the Pushshift API \t|\n\n----",
   "metadata": {
    "cell_id": "29cfbcf7-5d9d-48c2-9d75-2fa547a592cc",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Querying Pushshift API using Python\n\n\nThere are several parameters that can be passed to this search query. We will work through some of those parameters in this notebook. From here on, we will make use of `psaw` API. ",
   "metadata": {
    "cell_id": "a64809f3-9354-44ab-970c-8245a316cd2a",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.399993896484375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "57733f99-5d80-4f9d-89a3-a9a2d97ef2c1",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fdfcfc6c",
    "execution_start": 1645983182505,
    "execution_millis": 71,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 117
   },
   "source": "import pandas as pd\nfrom psaw import PushshiftAPI\n\n# This command instantiates an object, with methods that will be used through out the exercise:\napi = PushshiftAPI()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The instance `PushshiftAPI()` has two main functions \n1. `search_submissions` to query `/reddit/search/submission` endpoint\n2. `search_comments` to query `/reddit/search/comment` endpoint\n\n\nThere are lots of parameters taht the above two functions can take. You can check them out here - https://pushshift.io/api-parameters/. Their use will be highly dependent on what you want to do with these APIs, at which point, it's merely a matter of reading the documentation. We will be using some common parameters in the exercises that follow. ",
   "metadata": {
    "cell_id": "a036b463-cd39-49de-b1a0-1e39686a579c",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<div class=\"alert alert-info\">\n\n**Exercise 0.1:** We are going to start with collecting 50 most recents posts on Reddit, from the subreddit Ask me Anything (IAmA; https://www.reddit.com/r/AMA/) with more than 1,000 upvotes:\n</div>",
   "metadata": {
    "cell_id": "d889a77e-5896-43f5-ae84-7374ecc128c4",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "db04509e-85a6-434c-94e7-323fd533efd6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c15fdde6",
    "execution_start": 1645983186940,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "posts = api.search_submissions(subreddit='IAmA', score=\">1000\", limit=50)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "2c7de860-d6fa-42a1-8c2f-f10e6d559b29",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d7410215",
    "execution_start": 1645983191370,
    "execution_millis": 412,
    "deepnote_cell_type": "code"
   },
   "source": "type(posts) # what is the type of the above object",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "generator"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The API returns a generator object, which is an iterator over the list. We can only access the elements of this list through iteration in a sequential manner, i.e, we can not index on this generator like `posts[0]`. ",
   "metadata": {
    "cell_id": "0981c7fc-9100-435e-82eb-7f44992571a5",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 74.80000305175781
   }
  },
  {
   "cell_type": "markdown",
   "source": "<div class=\"alert alert-info\">\n\n**Exercise 0.2:** Make a pandas dataframe of the entries returned by the API\n</div>",
   "metadata": {
    "cell_id": "8b93992a-1cd9-493b-bc70-e5ba9061efc3",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "The code below is a list comprehension that loops through the generator and extracts relevant data for each matching Reddit post. It then turns that list into a Pandas DataFrame.\n\nNote: Each element of `posts` is of type `psaw.PushshiftAPI.submission` which is a special object. This object provides an attribute `d_` to extract a Python dictinary, with easier access to all collected attributes. We will use this attribute to build a better representation for our purpose.",
   "metadata": {
    "cell_id": "bf1754ff-238e-46eb-95aa-7e9244094b36",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.399993896484375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "fe600019-5c5b-4bf0-8554-f75009be6658",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "442db682",
    "execution_start": 1645983198393,
    "execution_millis": 1006,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 360
   },
   "source": "df_posts = pd.DataFrame([p.d_ for p in posts]) # We iterate over the generator",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/root/venv/lib/python3.7/site-packages/psaw/PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n  warnings.warn(shards_down_message)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<div class=\"alert alert-info\">\n\n**Exercise 0.3:** Now check for yourself the following - \n\n1. Number of rows and columns in the resulting dataframe \n2. The list of fieldnames that are returned by the API\n3. Look at 10 random rows of data only for the columns \"authors\", \"subreddit\", ‚Äútitle‚Äù, and upvote ‚Äúscore.‚Äù\n\n</div>",
   "metadata": {
    "cell_id": "46f05ec5-8bd3-4c00-a901-2934666fc0d7",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "7ac3e379-2fba-4d60-9d84-7a2cf35c87a3",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "de7e7e1b",
    "execution_start": 1645983200534,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Shape (nb of rows, nb of columns):\", df_posts.shape)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Shape (nb of rows, nb of columns): (50, 73)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "602f5d99-0123-4867-9903-212bd7b0cf55",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b2185722",
    "execution_start": 1645983201226,
    "execution_millis": 26,
    "deepnote_cell_type": "code"
   },
   "source": "# Which attributes do we now have access to?\ndf_posts.columns",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 7,
     "data": {
      "text/plain": "Index(['all_awardings', 'allow_live_comments', 'author',\n       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n       'author_flair_type', 'author_fullname', 'author_is_blocked',\n       'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post',\n       'contest_mode', 'created_utc', 'domain', 'full_link', 'gildings', 'id',\n       'is_created_from_ads_ui', 'is_crosspostable', 'is_meta',\n       'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable',\n       'is_self', 'is_video', 'link_flair_background_color',\n       'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id',\n       'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked',\n       'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n       'parent_whitelist_status', 'permalink', 'pinned', 'post_hint',\n       'preview', 'pwls', 'retrieved_on', 'score', 'selftext', 'send_replies',\n       'spoiler', 'stickied', 'subreddit', 'subreddit_id',\n       'subreddit_subscribers', 'subreddit_type', 'thumbnail', 'title',\n       'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url',\n       'whitelist_status', 'wls', 'created', 'edited', 'gilded',\n       'suggested_sort', 'author_flair_background_color',\n       'author_flair_text_color', 'author_flair_template_id',\n       'steward_reports', 'updated_utc'],\n      dtype='object')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "76b8f6e4-af1c-4979-97c1-8a0d738a473f",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "514b1a72",
    "execution_start": 1645983202477,
    "execution_millis": 80,
    "deepnote_cell_type": "code"
   },
   "source": "df_posts[['author', 'subreddit', 'title', 'score']].sample(10)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "application/vnd.deepnote.dataframe.v3+json": {
       "column_count": 4,
       "row_count": 10,
       "columns": [
        {
         "name": "author",
         "dtype": "object",
         "stats": {
          "unique_count": 9,
          "nan_count": 0,
          "categories": [
           {
            "name": "iamthatis",
            "count": 2
           },
           {
            "name": "mister4string",
            "count": 1
           },
           {
            "name": "7 others",
            "count": 7
           }
          ]
         }
        },
        {
         "name": "subreddit",
         "dtype": "object",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "categories": [
           {
            "name": "IAmA",
            "count": 10
           }
          ]
         }
        },
        {
         "name": "title",
         "dtype": "object",
         "stats": {
          "unique_count": 10,
          "nan_count": 0,
          "categories": [
           {
            "name": "On the first night of Christmas, a stranger gave to me...a new heart. IamA heart transplant recipient, AMA",
            "count": 1
           },
           {
            "name": "I am a full time nerd therapist! I run Dungeons &amp; Dragons, Minecraft, Roblox, Civ 6 and Fortnite as therapy. AMA!",
            "count": 1
           },
           {
            "name": "8 others",
            "count": 8
           }
          ]
         }
        },
        {
         "name": "score",
         "dtype": "int64",
         "stats": {
          "unique_count": 10,
          "nan_count": 0,
          "min": "1567",
          "max": "23850",
          "histogram": [
           {
            "bin_start": 1567,
            "bin_end": 3795.3,
            "count": 4
           },
           {
            "bin_start": 3795.3,
            "bin_end": 6023.6,
            "count": 0
           },
           {
            "bin_start": 6023.6,
            "bin_end": 8251.900000000001,
            "count": 1
           },
           {
            "bin_start": 8251.900000000001,
            "bin_end": 10480.2,
            "count": 0
           },
           {
            "bin_start": 10480.2,
            "bin_end": 12708.5,
            "count": 3
           },
           {
            "bin_start": 12708.5,
            "bin_end": 14936.800000000001,
            "count": 0
           },
           {
            "bin_start": 14936.800000000001,
            "bin_end": 17165.100000000002,
            "count": 0
           },
           {
            "bin_start": 17165.100000000002,
            "bin_end": 19393.4,
            "count": 1
           },
           {
            "bin_start": 19393.4,
            "bin_end": 21621.7,
            "count": 0
           },
           {
            "bin_start": 21621.7,
            "bin_end": 23850,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows": [
        {
         "author": "mister4string",
         "subreddit": "IAmA",
         "title": "On the first night of Christmas, a stranger gave to me...a new heart. IamA heart transplant recipie‚Ä¶",
         "score": 10490,
         "_deepnote_index_column": 17
        },
        {
         "author": "PerthNerdTherapist",
         "subreddit": "IAmA",
         "title": "I am a full time nerd therapist! I run Dungeons &amp; Dragons, Minecraft, Roblox, Civ 6 and Fortnit‚Ä¶",
         "score": 1567,
         "_deepnote_index_column": 2
        },
        {
         "author": "EmDawgrzz",
         "subreddit": "IAmA",
         "title": "I am a 19 year old gal making a living by working at a small, family-run slaughterhouse. AMA!",
         "score": 1885,
         "_deepnote_index_column": 4
        },
        {
         "author": "iamthatis",
         "subreddit": "IAmA",
         "title": "I'm Christian Selig, I used to work at Apple and now I work full-time on building the Apollo Reddit‚Ä¶",
         "score": 2674,
         "_deepnote_index_column": 28
        },
        {
         "author": "ReviewMeta",
         "subreddit": "IAmA",
         "title": "I'm Tommy, I built ReviewMeta - a site that detects \"fake\" reviews on Amazon. AMA!",
         "score": 19338,
         "_deepnote_index_column": 47
        },
        {
         "author": "meigom",
         "subreddit": "IAmA",
         "title": "My name is Meigo M√§rk and I walked 20,000 kilometers or 12,427 miles in 22 countries üë£üåç It took me ‚Ä¶",
         "score": 11523,
         "_deepnote_index_column": 42
        },
        {
         "author": "Rick_Smith_Axon",
         "subreddit": "IAmA",
         "title": "I am Rick Smith, the founder and CEO of Axon Enterprise. Years ago, we were almost brought down by ‚Ä¶",
         "score": 23850,
         "_deepnote_index_column": 15
        },
        {
         "author": "MainlyMozartSD",
         "subreddit": "IAmA",
         "title": "I'm the Principal Bass of the San Francisco Symphony. (I performed with Metallica!) In one week, I'‚Ä¶",
         "score": 6719,
         "_deepnote_index_column": 14
        },
        {
         "author": "PhilipRosedale",
         "subreddit": "IAmA",
         "title": "I am Philip Rosedale, founder of Second Life and High Fidelity. Ask me anything about immersive spa‚Ä¶",
         "score": 2665,
         "_deepnote_index_column": 13
        },
        {
         "author": "iamthatis",
         "subreddit": "IAmA",
         "title": "[Update on yesterday's Apollo SPCA Fundraiser] We raised $42,749.29 yesterday for the SPCA Animal S‚Ä¶",
         "score": 12560,
         "_deepnote_index_column": 26
        }
       ]
      },
      "text/plain": "                author subreddit  \\\n17       mister4string      IAmA   \n2   PerthNerdTherapist      IAmA   \n4            EmDawgrzz      IAmA   \n28           iamthatis      IAmA   \n47          ReviewMeta      IAmA   \n42              meigom      IAmA   \n15     Rick_Smith_Axon      IAmA   \n14      MainlyMozartSD      IAmA   \n13      PhilipRosedale      IAmA   \n26           iamthatis      IAmA   \n\n                                                title  score  \n17  On the first night of Christmas, a stranger ga...  10490  \n2   I am a full time nerd therapist! I run Dungeon...   1567  \n4   I am a 19 year old gal making a living by work...   1885  \n28  I'm Christian Selig, I used to work at Apple a...   2674  \n47  I'm Tommy, I built ReviewMeta - a site that de...  19338  \n42  My name is Meigo M√§rk and I walked 20,000 kilo...  11523  \n15  I am Rick Smith, the founder and CEO of Axon E...  23850  \n14  I'm the Principal Bass of the San Francisco Sy...   6719  \n13  I am Philip Rosedale, founder of Second Life a...   2665  \n26  [Update on yesterday's Apollo SPCA Fundraiser]...  12560  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>title</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>mister4string</td>\n      <td>IAmA</td>\n      <td>On the first night of Christmas, a stranger ga...</td>\n      <td>10490</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PerthNerdTherapist</td>\n      <td>IAmA</td>\n      <td>I am a full time nerd therapist! I run Dungeon...</td>\n      <td>1567</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EmDawgrzz</td>\n      <td>IAmA</td>\n      <td>I am a 19 year old gal making a living by work...</td>\n      <td>1885</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>iamthatis</td>\n      <td>IAmA</td>\n      <td>I'm Christian Selig, I used to work at Apple a...</td>\n      <td>2674</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>ReviewMeta</td>\n      <td>IAmA</td>\n      <td>I'm Tommy, I built ReviewMeta - a site that de...</td>\n      <td>19338</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>meigom</td>\n      <td>IAmA</td>\n      <td>My name is Meigo M√§rk and I walked 20,000 kilo...</td>\n      <td>11523</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Rick_Smith_Axon</td>\n      <td>IAmA</td>\n      <td>I am Rick Smith, the founder and CEO of Axon E...</td>\n      <td>23850</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>MainlyMozartSD</td>\n      <td>IAmA</td>\n      <td>I'm the Principal Bass of the San Francisco Sy...</td>\n      <td>6719</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>PhilipRosedale</td>\n      <td>IAmA</td>\n      <td>I am Philip Rosedale, founder of Second Life a...</td>\n      <td>2665</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>iamthatis</td>\n      <td>IAmA</td>\n      <td>[Update on yesterday's Apollo SPCA Fundraiser]...</td>\n      <td>12560</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 1: Extracting texts from Reddit posts\n\n<div class=\"alert alert-info\">\n\n**Exercise 1.1:** Let's now collect submissions related to the Oxford Internet Institute. \n- search for the exact keyword \"Oxford Internet Institute\", and select only posts with at least 10 upvotes\n- make a relevant dataframe where each row consists of a single entry returned by the API. \n- Check the number of rows and columns in the resulting dataframe\n</div>\n\nYou will have to check the parameters and their description here - https://github.com/pushshift/api#search-parameters-for-submissions. For example (make sure you double check the corresponding entries in the documentation),\n- `q` takes in the query, i.e., the keyword that you search for in the posts\n- `score` takes in a string to constrain the score range of the posts\n\n",
   "metadata": {
    "cell_id": "57da2710-d3dc-4589-bd91-f9bbb25ef825",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 100.39999389648438
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "bbf9c7d6-0d4d-4ca8-9133-cca4312d8a52",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f986bf6b",
    "execution_start": 1645983209293,
    "execution_millis": 9813,
    "output_cleared": true,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99,
    "deepnote_output_heights": [
     607
    ]
   },
   "source": "posts = # YOUR CODE HERE\ndf_posts = pd.DataFrame([p.d_ for p in posts])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\n<div class=\"alert alert-info\">\n\n**Exercise 1.2:** Let's look at some of the columns \n- have a look at the titles, number of comments, and the date\n- Can you interpret the date column? Head over to https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html and use `pd.to_datetime` for conversion of this column to an appropriate human-readable format. \n\n</div>",
   "metadata": {
    "cell_id": "68ef199a-1770-43b5-930c-8d8b8c876eeb",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3fc7c378-a975-458d-9e19-077e838e8a17",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5d910d05",
    "execution_start": 1645983219129,
    "execution_millis": 72,
    "output_cleared": true,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 342
   },
   "source": "# YOUR CODE HERE ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "6c9a7375-3597-4fce-8dec-e68f49d93337",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "26da718c",
    "execution_start": 1646037529722,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "# Reminder: this is all the columns you can access:\n# df_posts.columns",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\n<div class=\"alert alert-info\">\n\n**Exercise 1.3:** How would you list the subreddit of posts mentioning the OII?\n\n</div>\n",
   "metadata": {
    "cell_id": "cd1d8fc5-a909-47e8-a6fe-238d84cc0ae4",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "b7e22b3f-1c1f-4faa-9bd5-e31cd4e99ebb",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4b05a17f",
    "execution_start": 1645983227937,
    "execution_millis": 5,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "list_subreddits = # YOUR CODE HERE \nprint(list_subreddits)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\n<div class=\"alert alert-info\">\n\n**Exercise 1.4:** How would you list the usernames mentioning the OII?\n\n</div>\n",
   "metadata": {
    "cell_id": "31ea15bf-50db-49df-b1d9-ad3c7abcc0be",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "cd1b1982-d864-4d90-b931-800a8c9851b0",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f43c7d20",
    "execution_start": 1645983229535,
    "execution_millis": 4,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "list_usernames = # YOUR CODE HERE \nprint(list_usernames)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\n<div class=\"alert alert-info\">\n\n**Exercise 1.5:** Collect 100 posts related to ```policy``` regulation from the subreddits ```climatechange``` and ```datascience```. For this, modify the query below and the subreddit list:\n\n</div>",
   "metadata": {
    "cell_id": "af57ebbe-9297-4a25-9b77-a47e4ac0576d",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 74.80000305175781
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3b1efd11-8b9e-4b2d-91fc-2e4c7305bd7c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cc6117b0",
    "execution_start": 1645983232361,
    "execution_millis": 783,
    "output_cleared": true,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 796.2000122070312
   },
   "source": "query = \"policy\"\nsubreddit = \"climatechange,datascience\"\n\nposts = # YOUR CODE HERE \ndf_posts = pd.DataFrame([p.d_ for p in posts])\ndf_posts['created_utc'] = # YOUR CODE HERE \n\ndf_posts[['title', 'num_comments', 'created_utc']].sample(10)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 2: Accessing Comments in Reddit\n\nThe comments are accessible via the psaw method `api.search_comments`. For the list of acceptable parameters, head over https://github.com/pushshift/api#search-parameters-for-comments. \n\n<div class=\"alert alert-info\">\n\n**Exercise 2.1:** Search comments containing the words \"sociology\" with `score` greater than 1000. Do the following afterwards - \n- Make a dataframe of the entried returned by the query\n- convert the `created_utc` column to a more human-readable datetime format\n</div>\n\n",
   "metadata": {
    "cell_id": "85e828df-e539-41a3-bdf4-6965fafd1f95",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 136.8000030517578
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "bcdf1648-9da3-4ba9-8d8b-f52d6c7dcec6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c38626df",
    "execution_start": 1645983236101,
    "execution_millis": 9283,
    "output_cleared": true,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 246.1999969482422
   },
   "source": "comments = # YOUR CODE HERE \ncomments = pd.DataFrame([c.d_ for c in comments])\ncomments['created_utc'] = # YOUR CODE HERE ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<div class=\"alert alert-info\">\n\n**Exercise 2.2:** Let's look at the content of the comments\n- Check which key of the entries contain the content of the comments\n- have a look at the score, text and subreddit of the comments we collected\n</div>\n",
   "metadata": {
    "cell_id": "29094ab0-e518-4c45-b356-bfb4fb777fee",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "29122e6e-d962-46c7-8163-cdf9fd5471ef",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7c0f2877",
    "execution_start": 1645983245402,
    "execution_millis": 21,
    "output_cleared": true,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 598
   },
   "source": "comments[[\n    # YOUR CODE HERE: Comma separated list of columns \n    ]].sample(10)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "To search for multiple phrases in posts ‚Äî such as posts that mention sociology AND internet ‚Äî we can use parentheses and the bitwise AND operator &: `query = \"(sociology) & (internet)\"`\n\n<div class=\"alert alert-info\">\n\n**Exercise 2.3:** Let's look at the comments that contain the above query\n- make a dataframe of the entries returned by the above query\n- convert the `created_utc` column in a human-readable format\n- Sort the resulting dataframe by ascending value of their scores;  check out https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n- have a look at the score, text and subreddit of the comments we collected\n</div>\n",
   "metadata": {
    "cell_id": "c3b32ae4-b077-4181-861f-355859512aa7",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0fdccd54-74f2-4790-8e54-f6b7de17ddf3",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6578dd32",
    "execution_start": 1645983245428,
    "execution_millis": 778,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "query = \"(sociology) & (internet)\"\n\ncomments = # YOUR CODE HERE\ncomments = pd.DataFrame([c.d_ for c in comments])\ncomments['created_utc'] = # YOUR CODE HERE",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "53eed824-f5a2-49be-b0fb-db49832dd493",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "942f1de",
    "execution_start": 1645983245995,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "# Let's sort comments by decreasing score:\ncomments = # YOUR CODE HERE",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3100601c-e991-4439-a9ee-280b143b2e46",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "89d08070",
    "execution_start": 1645983245996,
    "execution_millis": 391,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# The top 10 comments:\n# YOUR CODE HERE",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 3: Accessing User data in Reddit\n\n<div class=\"alert alert-info\">\n\n**Exercise 3.1:** Find comments made by a user `nasa`: limit the query to 1000 entries. \n- Make a dataframe of the entries returned by the API\n- convert `created_utc` to a human-readable format\n- count the number of comments that `nasa` made on each subreddit. checkout https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html to do so.\n</div>",
   "metadata": {
    "cell_id": "19a36467-2e86-4172-96ab-2e82fa771a45",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 100.39999389648438
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "033b5a20-1619-444e-b994-388c79a601c3",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "51b42223",
    "execution_start": 1645983246013,
    "execution_millis": 9270,
    "output_cleared": true,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 264.20001220703125,
    "deepnote_output_heights": [
     21.1875,
     607
    ]
   },
   "source": "user_comments = # YOUR CODE HERE\ndf_user_comments = pd.DataFrame([c.d_ for c in user_comments])\ndf_user_comments['created_utc'] = # YOUR CODE HERE\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "534ca3a7-f557-4e7d-ba76-11d4c4a2f2aa",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e4f50b8e",
    "execution_start": 1645983255314,
    "execution_millis": 23,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "df_user_comments[['subreddit', 'created_utc']].sample(10)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4a582d06-cfb3-4e73-b1bc-dc8242107161",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "957eee61",
    "execution_start": 1645983255335,
    "execution_millis": 8,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# YOUR CODE HERE to count number of subreddits",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Homework: Subreddits of users that posts about OII\n\n\n<div class=\"alert alert-info\">\n\n- Write a function `subreddit_of_user` that takes in a string input `username` and returns a `list` of unique subreddits on which that `username` comments. \n- Find out all those posts with score `>10` that contain the keyword - \"Oxford Internet Institute\" \n- Find out the list of unique authors in the entries returned above\n- call `subreddit_of_user` on each of the authors found above\n</div>\n\n",
   "metadata": {
    "cell_id": "f09bcc10-09cd-44d7-b8a7-cd5156a7f462",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c925c49f-a2f7-4e79-9fb7-46c20fbd73a0",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "13d578e0",
    "execution_start": 1645983255344,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "def subreddits_of_user(username):\n    user_comments = # YOUR CODE HERE\n    df_user_comments = pd.DataFrame([c.d_ for c in user_comments])\n    \n    # YOUR CODE HERE\n    # return list of unique subreddits",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "35a4b826-2bad-45d1-8c5a-26b0e00a4cf0",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c28b548c",
    "execution_start": 1645983257296,
    "execution_millis": 46264,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "posts_oii =  # YOUR CODE HERE\ndf_posts_oii = pd.DataFrame([p.d_ for p in posts_oii])\n\nlist_of_usernames =  # YOUR CODE HERE: list of unique author names\n\nfor user in list_of_usernames:\n    print(user)\n    print(# YOUR CODE HERE)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f746e373-dc41-4dbe-b3f9-5f3af42ff658' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "40ecb169-10aa-40c1-83fa-adcd38021ed4",
  "deepnote_execution_queue": []
 }
}